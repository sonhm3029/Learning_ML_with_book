{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Machine Learning Lanscape\n",
    "\n",
    "## 1. Các loại hệ thống học máy\n",
    "\n",
    "### a) Supervised Learning \n",
    "Học có giám sát - tập data đã cho được đánh nhãn hết => Thường sử dụng bài toán Regression, dự đoán đầu ra với đầu vào cho trước.\n",
    "\n",
    "Các thuật toán thường dùng:\n",
    "\n",
    "- k-Nearest Neighbors\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Support Vector Machines (SVMs)\n",
    "- Decision Trees and Random Forests\n",
    "- Neural Network\n",
    "\n",
    "### b) Unsupervised learning\n",
    "Học không giám sát- tập data đã cho không được đánh nhãn => Thường sử dụng các bài toán phần loại\n",
    "\n",
    "Các thuật toán thường dùng\n",
    "\n",
    "- Clustering:\n",
    "    * K-means\n",
    "    * Hierarchical Cluster Analysis (HCA)\n",
    "    * Expectation Maximization\n",
    "- Visualization and dimensionality reduction\n",
    "    * Principal Componet Analysis (PCA)\n",
    "    * Kernel PCA\n",
    "    * Locally-Linear Embedding (LLE)\n",
    "    * t - distributed Stochastic Neighbor Embedding (t-SNE\n",
    "- Association rule learning\n",
    "    * Apriori\n",
    "    * Eclat\n",
    "\n",
    "### c) Semisupervised learning\n",
    "\n",
    "Học bán giám sát - tập data đã cho có môt phần được đánh nhãn và phần lớn là không được đánh nhãn.\n",
    "\n",
    "Các thuật toán thường dùng là sự kết hợp của học giám sát và không giám sát.\n",
    "\n",
    "### d) Reinforcement learning\n",
    "\n",
    "- Học củng cố - Thường dùng cho các bot trong game...\n",
    "\n",
    "### e) Batch and online learning\n",
    "\n",
    "#### Batch learning\n",
    "\n",
    "Sử dụng tất cả các data có để training => Sẽ không tốt khi có tập dataset quá lớn.\n",
    "\n",
    "Đối với loại này, data sẽ được training và sử dụng kết quả để deploy lên production. Trên production app, model sẽ không đươc training lại hay có bất kì thay đổi gì cả. Tuy nhiên ta cũng có thể training lại model theo schedule với tập dataset mới là kết hợp của nhứng data thu được khi chạy thực tế hoặc data thu thập được thêm kết hợp với data cũ dùng training model trước đây.\n",
    "\n",
    "#### Online learning\n",
    "\n",
    "Với `online learning`, hệ thống sẽ được train incrementally (train từng bước, dần dần) bằng cách cung cấp dữ liệu cho nó một cách tuấn tự\n",
    "\n",
    "![](../../../imgs/online_learning_1.png)\n",
    "\n",
    "Online learning có thể áp dụng để training với tập dataset lớn khi ta chia nhỏ tập dataset ra, load từng part của tập đã chia lên, training từng phần tuần tự cho đến khi hết tập dataset.\n",
    "\n",
    "Một tham số quan trọng của online learning system đó là nó có thể thích ứng với hệ thống nhanh thế nào, cái này gọi là `learning rate`. Nếu như ta có learning rate cao thì hệ thống sẽ mau thích ứng với data mới nhưng nó cũng sẽ nhanh chống quên đi data cũ ( mà chúng ta không muốn spam filter chỉ đánh flag mỗi các data mới nhất). Ngược lại, nếu như có learning rate nhỏ thì quá trình học của model sẽ chậm hơn nhưng nó cũng ít nhạy cảm hơn với nhiễu ở data mới.\n",
    "\n",
    "Một thử thách lớn đối với online learning đó là nếu như có những data xấu được cung cấp cho system, performance sẽ yếu đi. Nếu như \n",
    "system của ta là live thì nó sẽ gây sự chú ý cho client. Ví dụ nếu data xấu đến từ `malfunctioning sensor` của robot hay có ai đó cố tình spam search engine cố gắng để rank high in search results.\n",
    "\n",
    "Để giảm thiếu rủi ro trên, chúng ta cần giám sát hệ thống của mình một cách chặt chẽ và kịp thời, tắt tính năng học tập (và có thể trở lại trạng thái trước đó của model, system) nếu như phát hiện dấu hiệu giảm performance bất thường.\n",
    "\n",
    "### f) Instance-based versus Model-Based Learning\n",
    "\n",
    "#### Instance-based learning\n",
    "\n",
    "Cách học thông thường mà chúng ta thường thấy đó là việc `learn by heart` (Học thuộc lòng). Ví dụ như nếu ta muốn tạo một cái email spam filter vậy thì ta sẽ cần đánh flag trên các emails được xác định là spam emails có sẵn (việc đánh spams có thể được thực hiện bằng users).\n",
    "\n",
    "Bên cạnh việc đánh spam trên các email mới được `identical` to known spam emails thì spam filters cũng nên được lập trình đề đánh flag trên những email mới mà độ giống xác định với các `known spam emails`. Phương pháp đơn giản nhất để xác định mức độ giống nhau giữa các spam emails đó chính là so sánh xem chúng có số các `spam word` giống nhau là bao nhiêu.\n",
    "\n",
    "Vậy đây chính là phương pháp `instance-based learning`, system sẽ học thuộc lòng rồi sau đó áp dụng cho các case mới.\n",
    "\n",
    "#### Model-based learning\n",
    "\n",
    "Sử dụng tập dataset cho trước, xây dựng model dựa trên các thuật toán machine learning sau đó training model để model tìm ra mô hình tốt nhất cho việc predict dữ liệu mới\n",
    "\n",
    "\n",
    "#### Ví dụ cho training model predict life statisfaction dựa trên gdp của các quốc gia\n",
    "\n",
    "```Python\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "# Load the data\n",
    "oecd_bli = pd.read_csv(\"oecd_bli_2015.csv\", thousands=',')\n",
    "gdp_per_capita = pd.read_csv(\"gdp_per_capita.csv\",thousands=',',delimiter='\\t',\n",
    " encoding='latin1', na_values=\"n/a\")\n",
    "# Prepare the data\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X = np.c_[country_stats[\"GDP per capita\"]]\n",
    "y = np.c_[country_stats[\"Life satisfaction\"]]\n",
    "# Visualize the data\n",
    "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
    "plt.show()\n",
    "# Select a linear model\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "# Make a prediction for Cyprus\n",
    "X_new = [[22587]] # Cyprus' GDP per capita\n",
    "print(model.predict(X_new)) # outputs [[ 5.96242338]]\n",
    "```\n",
    "\n",
    "Nếu như model tạo ra prediction tốt thì ok, còn nêu skhoong thì cần phải điều chỉnh các hyper parameters, hoặc thêm data...\n",
    "\n",
    "Nói tóm lại:\n",
    "\n",
    "- Studied data\n",
    "- Selected a model\n",
    "- Trained model on training data\n",
    "- Apply model to make predictions on new cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Main Challenges of Machine Learning\n",
    "\n",
    "### a) Insufficient Quantity of Training data\n",
    "\n",
    "Data càng nhiều thì tỉ lệ chính xác của model sẽ được cải thiện hơn, vấn đề về lượng data training quá ít là một vấn đề đáng để quan tâm. Tuy nhiên cũng có những cách, thuật toán để làm tăng lương data training hơn từ tập training ban đầu.\n",
    "\n",
    "### b) Nonpresentative Training Data\n",
    "\n",
    "Khi training data mà data của ta không đáp ứng đủ các đại diện, các trường hợp... thì sẽ không cho ra model được đủ tốt. Ví dụ\n",
    "\n",
    "![](../../../imgs/online_learning_1.png)\n",
    "\n",
    "Như ta thấy thì nếu như tập dataset training chỉ có các điểm màu xanh thì model sẽ cho ra đường dự đoán là đường màu xanh dạng chấm. Đây là trường hợp bị miss một số quốc gia cho nên đối với dataset có đầy đủ các quốc gia thì model cho ra đường nét liền.\n",
    "\n",
    "### c) Poor-Quality Data\n",
    "\n",
    "Nếu như tập data của ta là tập data chưa được xử lý, có quá nhiều noise, outliers, ... thì sẽ gây ra mô hình không tốt.\n",
    "\n",
    "### d) Irrelevant Features\n",
    "\n",
    "Việc lựa chọn feature của data trong tập dataset để training cũng quan trọng vì nếu như chọn features không tốt thì model không tốt, vì vậy ta nên chọn ra các features tốt để training hoặc kết hợp các features đã có để cho ra được các features tốt hơn cho việc training, hoặc thu thập thêm data để có thêm features.\n",
    "\n",
    "### e) Overfitting the Training Data\n",
    "\n",
    "Overfitting (quá khớp) có thể xảy ra khi model quá phức tạp so với lượng và độ nhiễu của dữ liệu. Do đó có các solution như sau:\n",
    "\n",
    "- Làm cho model đơn giản hơn bằng cách chọn ít parameters hơn. Giảm số lượng attributes trong tập training data hoặc bằng cách constrain model\n",
    "\n",
    "- Thu thập thêm data\n",
    "\n",
    "- Giảm thiểu noise của training data.\n",
    "\n",
    "Constraining model để làm nó đơn giản hơn, làm giảm thiểu nhiễu được gọi là `regularization`.\n",
    "\n",
    "### f) Underfitting the Training Data\n",
    "\n",
    "Đây là ngược lại của Overfitting, cách để cải thiện , tránh underfitting:\n",
    "\n",
    "- Chọn model mạnh, nhiều parameters\n",
    "\n",
    "- Cung cấp các features tốt hơn cho model ( feature engineering)\n",
    "\n",
    "- Giảm constraints trên model.\n",
    "\n",
    "### g) Testing and Validating\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bài tập"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How would you define Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "Machine Learning is about build system to learning from data. Learning mean gettings better at some task, given some performance measure\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Học máy là một phương pháp xây dựng hệ thống có thể học từ data, có nghĩa là cung cấp cho hệ thống tập data và hệ thống sẽ `học` hay trở nên tốt hơn khi thực hiện task nào đó, với một số cách đánh giá performance nhất định."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Can you name four types of problems where it shines?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "Machine Learning is great for complex problems for which we have no algorith‐\n",
    "mic solution, to replace long lists of hand-tuned rules, to build systems that adapt\n",
    "to fluctuating environments, and finally to help humans learn (e.g., data mining)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is a labeled training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "A labeled training set is a training set that contains the desired solution (a.k.a. a\n",
    "label) for each instance\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Tập huấn luyện được đánh nhãn là tập dữ liệu mà đã bao gồm cả phương án giải quyết mong muốn cho mỗi trường hợp hay còn gọi là các nhãn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What are the two most common supervised tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "Two most common supervised tasks are classfication and regression\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Hai task phổ biến nhất của học giám sát là bài toán phân loại và hồi quy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. . Can you name four common unsupervised tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "Common unsupervised tasks include clustering, visualization, dimensionality reduction, and asscociation rule learning\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Các common task của học không giám sát bao gồm:\n",
    "\n",
    "- Phân cụm\n",
    "\n",
    "- Mô tả (Visulization)\n",
    "\n",
    "- Giảm số chiều dữ liệu\n",
    "\n",
    "- Khai phá các quy luật kết hợp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What type of Machine Learning algorithm would you use to allow a robot to walk in various unknown terrains?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "Reinforcement Learning is likely to perform best if we want a robot to learn to walk in various unknown terrains since this is typically the type of problem that Reinforcement Learning tackles. It might be possible to express the problem as a supervised or semisupervised learning problem, but it would be less natural.\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Thuật toán học máy dùng đó là học củng cố.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. What type of algorithm would you use to segment your customers into multiple groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Anh:**\n",
    "\n",
    "If you don’t know how to define the groups, then you can use a clustering algorithm (unsupervised learning) to segment your customers into clusters of similar customers. However, if you know what groups you would like to have, then you can feed many examples of each group to a classification algorithm (supervised learning), and it will classify all your customers into these groups.\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Ta có thể dùng bài toán phần cụm (clustering) để thực hiện nếu như ta chưa biết rõ hay chưa định nghĩa các nhóm cần phần cụm (hay là chưa có nhãn cho dữ liệu). Còn trong trường hợp đã biết các nhóm cần phân cụm rồi thì ta có thể sử dụng bài toán `classification` (đã có nhãn có dữ liệu ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "Spam detection is a typical supervised learning problem: the algorithm is fed many emails along with their label (spam or not spam).\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Đây là bài toán điển hình của `classification` trong học giám sát khi ta đã biết nhãn của email spam và không spam qua đó thực hiện phân loại được đâu là spam emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. What is an online learning system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "An online learning system can learn incrementally, as opposed to a batch learning system. This makes it capable of adapting rapidly to both changing data and autonomous systems, and of training on very large quantities of data.\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Online learning là hệ thống học dần dần, học cả trong quá trình đã được đưa lên production. Việc này giúp hệ thống có khảng năng thích ứng nhanh chóng với việc thay đổi data và hệ thống tự động, ngoài ra còn thích hợp cho việc training lượng lớn dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. What is out-of-core learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-core algorithms can handle vast quantities of data that cannot fit in a computer’s main memory. An out-of-core learning algorithm chops the data into mini-batches and uses online learning techniques to learn from these minibatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. . What type of learning algorithm relies on a similarity measure to make predictions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "An instance-based learning system learns the training data by heart; then, when given a new instance, it uses a similarity measure to find the most similar learned instances and uses them to make predictions\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Instance-based learning là hệ thống học thuộc lòng, dự đoán data mới dựa vào sự giống nhau của nó với data đã biết trước."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. What is the difference between a model parameter and a learning algorithm’s hyperparameter?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". A model has one or more model parameters that determine what it will predict given a new instance (e.g., the slope of a linear model). A learning algorithm tries to find optimal values for these parameters such that the model generalizes well to new instances. A hyperparameter is a parameter of the learning algorithm itself, not of the model (e.g., the amount of regularization to apply)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. What do model-based learning algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-based learning algorithms search for an optimal value for the model\n",
    "parameters such that the model will generalize well to new instances. We usually train such systems by minimizing a cost function that measures how bad the system is at making predictions on the training data, plus a penalty for model complexity if the model is regularized. To make predictions, we feed the new instance’s features into the model’s prediction function, using the parameter values found by the learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Can you name four of the main challenges in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the main challenges in Machine Learning are:\n",
    " \n",
    "- The lack of data\n",
    "- Poor data quality\n",
    "- nonrepresentative data\n",
    "- Uninformative features \n",
    "- excessively simple models that underfit the training data, and excessively complex models that overfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. If your model performs great on the training data but generalizes poorly to instances, what is happening? Can you name three possible solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "If a model performs great on the training data but generalizes poorly to new instances, the model is likely overfitting the training data (or we got extremely lucky on the training data). Possible solutions to overfitting are getting more data, simplifying the model (selecting a simpler algorithm, reducing the number of parameters or features used, or regularizing the model), or reducing the noise in the training data.\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Đây là hiện tượng học quá khớp (overfitting). Các giải pháp là:\n",
    "\n",
    "- Thu thập nhiều data hơn\n",
    "- Làm cho model đơn giản hơn\n",
    "- Giảm thiếu số parameters, features dùng \n",
    "- Regularizing model\n",
    "- Giảm nhiễu trên tập huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. What is a test set and why would you want to use it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "A test set is used to estimate the generalization error that a model will make on new instances, before the model is launched in production.\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Tập test là tập dùng để đánh giá xem model sẽ có độ chính xác hay sai số thế nào trên các data mới trước khi nó được đưa lên production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. What is the purpose of a validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "A validation set is used to compare models. It makes it possible to select the best model and tune the hyperparameters.\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Tập validation set là tập dùng để so sánh các models, hay đánh giá mức độ tốt của model giúp cho chọn ra model tốt nhất hay các hyperparameters tốt nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. What can go wrong if you tune hyperparameters using the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Anh:**\n",
    "\n",
    "If you tune hyperparameters using the test set, you risk overfitting the test set, and the generalization error you measure will be optimistic (you may launch a model that performs worse than you expect).\n",
    "\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Việc này sẽ làm cho mô hình overfitting vì đây không khác gì cách học tủ trên toàn bộ các data đã có"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. What is cross-validation and why would you prefer it to a validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh:**\n",
    "\n",
    "Cross-validation is a technique that makes it possible to compare models (for model selection and hyperparameter tuning) without the need for a separate validation set. This saves precious training data.\n",
    "\n",
    "**Việt:**\n",
    "\n",
    "Đây là phương pháp chia tập training set ra làm `training set` và `validation set` giúp tận dụng data nếu như lượng data có là ít."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a99539085cd3bdd5c32c96cfbe8da0377cdfd87c78a129b6678f1e2495c8398d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
